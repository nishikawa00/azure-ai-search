{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this tutorial, we'll demonstrate how to leverage a sample dataset stored in Azure Cosmos DB for MongoDB vCore to ground OpenAI models. We'll do this taking advantage of Azure Cosmos DB for Mongo DB vCore's [vector similarity search](https://learn.microsoft.com/azure/cosmos-db/mongodb/vcore/vector-search) functionality. In the end, we'll create an interatice chat session with the GPT-3.5 completions model to answer questions about Azure services informed by our dataset. This process is known as Retrieval Augmented Generation, or RAG.\n",
    "\n",
    "This tutorial borrows some code snippets and example data from the Azure Cognitive Search Vector Search demo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries <a class=\"anchor\" id=\"preliminaries\"></a>\n",
    "First, let's start by installing the packages that we'll need later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy\n",
    "! pip install openai\n",
    "! pip install pymongo\n",
    "! pip install python-dotenv\n",
    "! pip install azure-core\n",
    "! pip install azure-cosmos\n",
    "! pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from azure.core.exceptions import AzureError\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import pymongo\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use the example.env as a template to provide the necessary keys and endpoints in your own .env file.\n",
    "Make sure to modify the env_name accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"example.env\" # following example.env template change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "cosmosdb_endpoint = config['cosmos_db_api_endpoint']\n",
    "cosmosdb_key = config['cosmos_db_api_key']\n",
    "cosmosdb_connection_str = config['cosmos_db_connection_string']\n",
    "\n",
    "COSMOS_MONGO_USER = config['cosmos_db_mongo_user']\n",
    "COSMOS_MONGO_PWD = config['cosmos_db_mongo_pwd']\n",
    "COSMOS_MONGO_SERVER = config['cosmos_db_mongo_server']\n",
    "\n",
    "openai.api_type = config['openai_api_type']\n",
    "openai.api_key = config['openai_api_key']\n",
    "openai.api_base = config['openai_api_endpoint']\n",
    "openai.api_version = config['openai_api_version']\n",
    "embeddings_deployment = config['openai_embeddings_deployment']\n",
    "completions_deployment = config['openai_completions_deployment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure Cosmos DB for MongoDB vCore resource<a class=\"anchor\" id=\"cosmosdb\"></a>\n",
    "Let's start by creating an Azure Cosmos DB for MongoDB vCore Resource following this quick start guide: https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/quickstart-portal\n",
    "\n",
    "Then copy the connection details (server, user, pwd) into the config.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI <a class=\"anchor\" id=\"azureopenai\"></a>\n",
    "\n",
    "Finally, let's setup our Azure OpenAI resource Currently, access to this service is granted only by application. You can apply for access to Azure OpenAI by completing the form at https://aka.ms/oai/access. Once you have access, complete the following steps:\n",
    "\n",
    "- Create an Azure OpenAI resource following this quickstart: https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource?pivots=web-portal\n",
    "- Deploy a `completions` and `embeddings` model \n",
    "    - For more information on `completions`, go here: https://learn.microsoft.com/azure/ai-services/openai/how-to/completions\n",
    "    - For more information on `embeddings`, go here: https://learn.microsoft.com/azure/ai-services/openai/how-to/embeddings\n",
    "- Copy the endpoint, key, deployment names for (embeddings model, completions model) into the config.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and create embeddings <a class=\"anchor\" id=\"loaddata\"></a>\n",
    "Here we load a sample dataset containing descriptions of Azure services, then we use Azure OpenAI to create vector embeddings from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text-sample.json data file. Embeddings will need to be generated using the function below.\n",
    "#data_file = open(file=\"../../DataSet/AzureServices/text-sample.json\", mode=\"r\")\n",
    "\n",
    "# OR Load text-sample_w_embeddings.json which has embeddings pre-computed\n",
    "data_file = open(file=\"../../DataSet/AzureServices/text-sample_w_embeddings.json\", mode=\"r\") \n",
    "data = json.load(data_file)\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take a peek at one data item\n",
    "print(json.dumps(data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(10))\n",
    "def generate_embeddings(text):\n",
    "    '''\n",
    "    Generate embeddings from string of text.\n",
    "    This will be used to vectorize data and user input for interactions with Azure OpenAI.\n",
    "    '''\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=\"text-embedding-ada-002\")\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    time.sleep(0.5) # rest period to avoid rate limiting on AOAI for free tier\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for title and content fields\n",
    "n = 0\n",
    "for item in data:\n",
    "    n+=1\n",
    "    title = item['title']\n",
    "    content = item['content']\n",
    "    title_embeddings = generate_embeddings(title)\n",
    "    content_embeddings = generate_embeddings(content)\n",
    "    item['titleVector'] = title_embeddings\n",
    "    item['contentVector'] = content_embeddings\n",
    "    item['@search.action'] = 'upload'\n",
    "    print(\"Creating embeddings for item:\", n, \"/\" ,len(data), end='\\r')\n",
    "# Save embeddings to sample_text_w_embeddings.json file\n",
    "with open(\"../../DataSet/AzureServices/text-sample_w_embeddings.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect and setup Cosmos DB for MongoDB vCore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_conn = \"mongodb+srv://\"+COSMOS_MONGO_USER+\":\"+COSMOS_MONGO_PWD+\"@\"+COSMOS_MONGO_SERVER+\"?tls=true&authMechanism=SCRAM-SHA-256&retrywrites=false&maxIdleTimeMS=120000\"\n",
    "mongo_client = pymongo.MongoClient(mongo_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set up the DB and collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database called TutorialDB\n",
    "db = mongo_client['ExampleDB']\n",
    "\n",
    "# Create collection if it doesn't exist\n",
    "COLLECTION_NAME = \"ExampleCollection\"\n",
    "\n",
    "collection = db[COLLECTION_NAME]\n",
    "\n",
    "if COLLECTION_NAME not in db.list_collection_names():\n",
    "    # Creates a unsharded collection that uses the DBs shared throughput\n",
    "    db.create_collection(COLLECTION_NAME)\n",
    "    print(\"Created collection '{}'.\\n\".format(COLLECTION_NAME))\n",
    "else:\n",
    "    print(\"Using collection: '{}'.\\n\".format(COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use only if re-reunning code and want to reset db and collection\n",
    "collection.drop_index(\"VectorSearchIndex\")\n",
    "mongo_client.drop_database(\"ExampleDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the vector index\n",
    "\n",
    "**IMPORTANT: You can only create one index per vector property.** That is, you cannot create more than one index that points to the same vector property. If you want to change the index type (e.g., from IVF to HNSW) you must drop the index first before creating a new index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IVF\n",
    "IVF is the default vector indexing algorithm, which works on all cluster tiers. It's an approximate nerarest neighbors (ANN) approach that uses clustering to speeding up the search for similar vectors in a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.command({\n",
    "  'createIndexes': 'ExampleCollection',\n",
    "  'indexes': [\n",
    "    {\n",
    "      'name': 'VectorSearchIndex',\n",
    "      'key': {\n",
    "        \"contentVector\": \"cosmosSearch\"\n",
    "      },\n",
    "      'cosmosSearchOptions': {\n",
    "        'kind': 'vector-ivf',\n",
    "        'numLists': 1,\n",
    "        'similarity': 'COS',\n",
    "        'dimensions': 1536\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HNSW (preview)\n",
    "\n",
    "HNSW stands for Hierarchical Navigable Small World, a graph-based data structure that partitions vectors into clusters and subclusters. With HNSW, you can perform fast approximate nearest neighbor search at higher speeds with greater accuracy. HNSW is an approximate (ANN) method. As a preview feature, this must be enabled using Azure Feature Enablement Control (AFEC) by selecting the \"mongoHnswIndex\" feature. For more information, see [enable preview features](https://learn.microsoft.com/azure/azure-resource-manager/management/preview-features).\n",
    "\n",
    "HNSW works on M50 cluster tiers and higher while in preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.command(\n",
    "{ \n",
    "    \"createIndexes\": \"ExampleCollection\",\n",
    "    \"indexes\": [\n",
    "        {\n",
    "            \"name\": \"VectorSearchIndex\",\n",
    "            \"key\": {\n",
    "                \"contentVector\": \"cosmosSearch\"\n",
    "            },\n",
    "            \"cosmosSearchOptions\": { \n",
    "                \"kind\": \"vector-hnsw\", \n",
    "                \"m\": 16, # default value \n",
    "                \"efConstruction\": 64, # default value \n",
    "                \"similarity\": \"COS\", \n",
    "                \"dimensions\": 1536\n",
    "            } \n",
    "        } \n",
    "    ] \n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to the collection\n",
    "A simple `insert_many()` to insert our data in JSON format into the newly created DB and collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.insert_many(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Search in Cosmos DB for MongoDB vCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to assist with vector search\n",
    "def vector_search(query, num_results=3):\n",
    "    query_embedding = generate_embeddings(query)\n",
    "    embeddings_list = []\n",
    "    pipeline = [\n",
    "        {\n",
    "            '$search': {\n",
    "                \"cosmosSearch\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"path\": \"contentVector\",\n",
    "                    \"k\": num_results #, \"efsearch\": 40 # optional for HNSW only \n",
    "                },\n",
    "                \"returnStoredSource\": True }},\n",
    "        {'$project': { 'similarityScore': { '$meta': 'searchScore' }, 'document' : '$$ROOT' } }\n",
    "    ]\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a test query below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"What are the services for running ML models?\"\n",
    "results = vector_search(query)\n",
    "for result in results: \n",
    "#     print(result)\n",
    "    print(f\"Similarity Score: {result['similarityScore']}\")  \n",
    "    print(f\"Title: {result['document']['title']}\")  \n",
    "    print(f\"Content: {result['document']['content']}\")  \n",
    "    print(f\"Category: {result['document']['category']}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A over the data with GPT-3.5\n",
    "\n",
    "Finally, we'll create a helper function to feed prompts into the `Completions` model. Then we'll create interactive loop where you can pose questions to the model and receive information grounded in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function helps to ground the model with prompts and system instructions.\n",
    "\n",
    "def generate_completion(prompt):\n",
    "    system_prompt = '''\n",
    "    You are an intelligent assistant for Microsoft Azure services.\n",
    "    You are designed to provide helpful answers to user questions about Azure services given the information about to be provided.\n",
    "        - Only answer questions related to the information provided below, provide 3 clear suggestions in a list format.\n",
    "        - Write two lines of whitespace between each answer in the list.\n",
    "        - Only provide answers that have products that are part of Microsoft Azure.\n",
    "        - If you're unsure of an answer, you can say \"\"I don't know\"\" or \"\"I'm not sure\"\" and recommend users search themselves.\"\n",
    "    '''\n",
    "\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_input},\n",
    "    ]\n",
    "\n",
    "    for item in results:\n",
    "        messages.append({\"role\": \"system\", \"content\": prompt['content']})\n",
    "\n",
    "    response = openai.ChatCompletion.create(engine=completions_deployment, messages=messages)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loop of user input and model output. You can now perform Q&A over the sample data!\n",
    "\n",
    "user_input = \"\"\n",
    "print(\"*** Please ask your model questions about Azure services. Type 'end' to end the session.\\n\")\n",
    "user_input = input(\"Prompt: \")\n",
    "while user_input.lower() != \"end\":\n",
    "    results_for_prompt = vector_search(user_input)\n",
    "   # print(f\"User Prompt: {user_input}\")\n",
    "    completions_results = generate_completion(results_for_prompt)\n",
    "    print(\"\\n\")\n",
    "    print(completions_results['choices'][0]['message']['content'])\n",
    "    user_input = input(\"Prompt: \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

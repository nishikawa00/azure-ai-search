{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "import numpy as np\n",
    "import os\n",
    "#from embedder import OpenAIEmbedder\n",
    "#from searcher import CosineNearestNeighborsFinder\n",
    "#from chatBot import GPTBasedChatBot\n",
    "\n",
    "# 環境変数を取得（OpenAI Key) \n",
    "env_name = \"example.env\" # following example.env template change to your own .env file name\n",
    "config = dotenv_values(os.path.join(os.getcwd(), env_name), encoding='UTF-16LE')\n",
    "api_key = config['openai_api_key']\n",
    "#OpenAI.api_key = api_key\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG用データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル化するデータセット\n",
    "texts = [\n",
    "    \"佐藤一郎は、東京生まれの35歳のプログラマーです。趣味は写真撮影とハイキング。新しい技術を学ぶことに情熱を注いでいます。\",\n",
    "    \"鈴木花子は、北海道出身の28歳のイラストレーターです。猫を二匹飼っており、自然と動物を愛する心優しい人物です。\",\n",
    "    \"田中健二は、大阪で小さなカフェを経営する45歳の起業家です。コーヒーに対する深い知識と情熱を持ち、地域社会に貢献しています。\",\n",
    "    \"山本美咲は、福岡県出身の22歳の大学生です。法律を専攻しており、将来は人権に関わる仕事に就きたいと考えています。\",\n",
    "    \"伊藤高志は、長野県の山の中で育った30歳の写真家です。自然の美しさを捉えることに特化し、国内外で展示会を開催しています。\",\n",
    "    \"小林由紀子は、沖縄県出身の40歳の小学校教師です。子どもたちに芸術と文化の大切さを教えることに生きがいを感じています。\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG用データセットのベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedderインターフェースの実装\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "    # openai 1.10.0 で動作確認\n",
    "    response = client.embeddings.create(input=texts, model=\"text-embedding-3-small\")\n",
    "    # レスポンスからベクトルを抽出\n",
    "    return [data.embedding for data in response.data]\n",
    "\n",
    "def save(texts: list[str], filename: str) -> bool:\n",
    "    vectors = embed(texts)\n",
    "    data_to_save = [\n",
    "        {\"id\": idx, \"text\": text, \"vector\": vector}\n",
    "        for idx, (text, vector) in enumerate(zip(texts, vectors))\n",
    "    ]\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data_to_save, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"{filename} に保存されました。\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB構築（jsonファイル形式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data.json に保存されました。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データベクトル化とjsonファイル格納\n",
    "save(texts, \"sample_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベクトル類似度検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cosine_similarity(vec1: list[float], vec2: list[float]) -> float:\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    # openAI embeddingのベクトルを対象にする場合は正規化されているため、np.dot(vec1, vec2) だけでも良い\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def find_nearest(data, vector: list[float], topk: int = 1) -> list[dict]:\n",
    "    similarities = [\n",
    "        (idx, _cosine_similarity(vector, item[\"vector\"]))\n",
    "        for idx, item in enumerate(data)\n",
    "    ]\n",
    "    # 類似度が高い順にソート\n",
    "    sorted_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    # Top-Kの結果を返す\n",
    "    return [data[idx] for idx, _ in sorted_similarities[:topk]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIチャットボット回答の作成（プロンプト+RAG検索結果）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_query: str, refs: list[str]) -> str:\n",
    "\n",
    "    # GPTによる応答を生成\n",
    "    context = \"\\n\".join(refs) + \"\\n\" #文字列を連結。連結毎に改行。\n",
    "\n",
    "    prompt = f\"以下の情報に基づいてユーザーの質問に答えてください:\\n\\n{context}\\n\\n質問: {user_query}\\n答え:\"\n",
    "    #print(\"#\" * 30)\n",
    "    #print(\"#\" * 30)\n",
    "    print(f\"\\nprompt:\\n {prompt}\\n\") # f\"{<変数>}\"\n",
    "    #print(\"#\" * 30)\n",
    "    #print(\"#\" * 30)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSONファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(data_file: str) -> list[dict]:\n",
    "    with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIチャットボットに対するメイン処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refs:['小林由紀子は、沖縄県出身の40歳の小学校教師です。子どもたちに芸術と文化の大切さを教えることに生きがいを感じています。', '伊藤高志は、長野県の山の中で育った30歳の写真家です。自然の美しさを捉えることに特化し、国内外で展示会を開催しています。']\n",
      "context:小林由紀子は、沖縄県出身の40歳の小学校教師です。子どもたちに芸術と文化の大切さを教えることに生きがいを感じています。\n",
      "伊藤高志は、長野県の山の中で育った30歳の写真家です。自然の美しさを捉えることに特化し、国内外で展示会を開催しています。\n",
      "\n",
      "\n",
      "prompt:\n",
      " 以下の情報に基づいてユーザーの質問に答えてください:\n",
      "\n",
      "小林由紀子は、沖縄県出身の40歳の小学校教師です。子どもたちに芸術と文化の大切さを教えることに生きがいを感じています。\n",
      "伊藤高志は、長野県の山の中で育った30歳の写真家です。自然の美しさを捉えることに特化し、国内外で展示会を開催しています。\n",
      "\n",
      "\n",
      "質問: アートを教えられる先生を探しています\n",
      "答え:\n",
      "\n",
      "【AIの返答】\n",
      "小林由紀子先生は芸術と文化の教育に生きがいを感じている小学校教師です。彼女がアートを教えることに熱心であるため、彼女が適格な候補の一人となります。\n"
     ]
    }
   ],
   "source": [
    "data = _load_data(\"sample_data.json\")\n",
    "user_query: str = \"アートを教えられる先生を探しています\" # <変数>:<データ型>で、変数を宣言可能\n",
    "user_query_vector: list[float] = embed([user_query])[0]\n",
    "\n",
    "search_results: list[dict] = find_nearest(data, user_query_vector, topk=2)\n",
    "\n",
    "response: str = generate_response(\n",
    "    user_query, [search_result[\"text\"] for search_result in search_results]\n",
    ")\n",
    "\n",
    "#print(\"*\" * 30)\n",
    "#print(\"*\" * 30)\n",
    "print(\"【AIの返答】\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "banana\n",
      "cherry\n"
     ]
    }
   ],
   "source": [
    "# リストの例\n",
    "refs = [\"apple\", \"banana\", \"cherry\"]\n",
    "\n",
    "# 要素を改行で連結して context 変数に代入\n",
    "context = \"\\n\".join(refs)\n",
    "\n",
    "# context の中身を表示\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prompt:\n",
      "\n",
      " ユーザーの入力を受け付けてください\n"
     ]
    }
   ],
   "source": [
    "# 仮のpromptの値\n",
    "prompt = \"ユーザーの入力を受け付けてください\"\n",
    "\n",
    "# f文字列を使ってpromptの値を表示\n",
    "print(f\"\\nprompt:\\n\\n {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ユーザーのクエリ: これはテストです, 参照データ: ['参照1', '参照2']\n"
     ]
    }
   ],
   "source": [
    "def generate_response(user_query: str, refs: list[str]) -> str:\n",
    "    # ここに処理を実装する（例えば、ユーザークエリと参照データを組み合わせて適切な応答を生成する）\n",
    "    response = f\"ユーザーのクエリ: {user_query}, 参照データ: {refs}\"\n",
    "    return response\n",
    "\n",
    "# 関数を呼び出す\n",
    "user_query = \"これはテストです\"\n",
    "refs = [\"参照1\", \"参照2\"]\n",
    "result = generate_response(user_query, refs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
